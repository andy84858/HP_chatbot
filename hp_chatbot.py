__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
import streamlit as st
import boto3
import os
import tarfile
import langid
from langchain.prompts import ChatPromptTemplate
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
import openai

# è¨­ç½® OpenAI API å¯†é‘°

# client = OpenAI(
#     api_key=st.secrets["OPENAI_API_KEY"]
# )
# os.environ['OPENAI_API_KEY'] = st.secrets["OPENAI_API_KEY"]
# client = OpenAI(api_key=st.secrets["openai_api_key"])
openai.api_key = st.secrets.get("OPENAI_API_KEY")
os.environ["OPENAI_API_KEY"] = openai.api_key

# è¨­ç½® AWS èªè­‰
aws_access_key_id = st.secrets.get("AWS_ACCESS_KEY_ID")
aws_secret_access_key = st.secrets.get("AWS_SECRET_ACCESS_KEY")

if not aws_access_key_id or not aws_secret_access_key:
    st.error("AWS credentials not found in secrets. Please add them to your Streamlit secrets.")
    st.stop()

# å‰µå»º S3 å®¢æˆ¶ç«¯
try:
    s3 = boto3.client('s3',
                      aws_access_key_id=aws_access_key_id,
                      aws_secret_access_key=aws_secret_access_key)
    # æ¸¬è©¦ S3 é€£æ¥
    s3.list_buckets()
    st.success("Successfully connected to AWS S3")
except Exception as e:
    st.error(f"Error connecting to AWS S3: {str(e)}")
    st.stop()

@st.cache_resource
def load_db_from_s3(lang):
    bucket_name = st.secrets["S3_BUCKET_NAME"]
    file_name = f'hp_{lang}_database.tar.gz'
    local_file = f'/tmp/hp_{lang}_database.tar.gz'
    local_dir = f'/tmp/hp_{lang}_database'

    try:
        # Download files from S3 bucket
        s3.download_file(bucket_name, file_name, local_file)

        # Unzip files
        with tarfile.open(local_file, 'r:gz') as tar:
            tar.extractall(path='/tmp')

        # Laod Chroma dataset
        embedding_function = OpenAIEmbeddings()
        db = Chroma(persist_directory=local_dir, embedding_function=embedding_function)

        st.success(f"Successfully loaded {lang.upper()} database")
        return db
    except Exception as e:
        st.error(f"Error loading {lang.upper()} database: {str(e)}")
        return None

# åŠ è½½ä¸­è‹±æ–‡æ•°æ®åº“Load CN/EN database
@st.cache_resource
def load_databases():
    cn_db = load_db_from_s3('cn')
    en_db = load_db_from_s3('en')
    return cn_db, en_db

cn_db, en_db = load_databases()


# å‰µå»ºèŠå¤©æ¨¡å‹
chat_model = ChatOpenAI(model_name="gpt-4o-mini")

def detect_language(text):
    lang, _ = langid.classify(text)
    return 'zh' if lang == 'zh' else 'en'

def generate_response(query, language, chat_history):
    db = cn_db if language == 'zh' else en_db
    if db is None:
        return "I'm sorry, but the required database is not available at the moment. Please try again later."

    results = db.similarity_search_with_relevance_scores(query, k=5)
    context = "\n".join([doc.page_content for doc, _ in results])
    # å°‡èŠå¤©æ­·å²è½‰æ›ç‚ºstræ ¼å¼
    history_str = "\n".join([f"Human: {msg['content']}" if msg['role'] == 'user' else f"AI: {msg['content']}" for msg in chat_history])

    if language == 'zh':
        prompt_template = ChatPromptTemplate.from_template(
            "ä½ æ˜¯ä¸€å€‹å°ˆé–€å›ç­”é—œæ–¼å“ˆåˆ©æ³¢ç‰¹å•é¡Œçš„AIåŠ©æ‰‹ã€‚è«‹è€ƒæ…®ä»¥ä¸‹å°è©±æ­·å²ï¼Œä¸¦ä»¥å°ç£ç¿»è­¯çš„ç¹é«”ä¸­æ–‡ç‰ˆå°èªªçš„è§’è‰²ã€åœ°åã€ç‰©å“åç¨±å›ç­”æœ€æ–°çš„å•é¡Œï¼š\n\n"
            "å¦‚æœä¸Šä¸‹æ–‡ä¸­ä¸¦æœªæåˆ°å…·é«”è¨Šæ¯ï¼Œè«‹ä¾ä½ å°å“ˆåˆ©æ³¢ç‰¹å°èªªç¹é«”ä¸­æ–‡ç‰ˆçš„ç†è§£é€²è¡Œå›ç­”"
            "å°è©±æ­·å²ï¼š\n{history}\n\n"
            "ä¸Šä¸‹æ–‡ï¼š\n{context}\n\n"
            "Human: {query}\n"
            "AI: "
        )
    else:
        prompt_template = ChatPromptTemplate.from_template(
            "You are an AI assistant specializing in answering questions about Harry Potter. "
            "Please consider the following conversation history and answer the latest question in English:\n\n"
            "If context contains no specific content, please answer the question based on your understanding to the Harry Potter novels"
            "Conversation history:\n{history}\n\n"
            "Context:\n{context}\n\n"
            "Human: {query}\n"
            "AI: "
        )

    prompt = prompt_template.format(history=history_str, context=context, query=query)
    response = chat_model.invoke(prompt)

    return response.content

def main():
    st.title("âš¡ğŸ§¹Harry Potter Chatbot âš¡ğŸ§¹")

    # åˆå§‹åŒ–èŠå¤©æ­·å²
    if 'messages' not in st.session_state:
        st.session_state.messages = []

    # é¡¯ç¤ºèŠå¤©æ­·å²
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # æ¥å—ç”¨æˆ¶è¼¸å…¥
    if prompt := st.chat_input("What would you like to know about Harry Potter?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # æª¢æ¸¬èªè¨€ä¸¦ç”Ÿæˆå›æ‡‰
        language = detect_language(prompt)
        response = generate_response(prompt, language, st.session_state.messages)

        # é¡¯ç¤ºåŠ©æ‰‹å›æ‡‰
        with st.chat_message("assistant"):
            st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})

    # æ·»åŠ å´é‚Šæ¬„èªªæ˜
    st.sidebar.title("About")
    st.sidebar.info(
        "This chatbot can answer questions about Harry Potter novels in both English and Traditional Chinese. "
        "Simply type your question in either language, and the bot will respond accordingly."
    )
    st.sidebar.info(
        "é€™å€‹èŠå¤©æ©Ÿå™¨äººå¯ä»¥ç”¨ç¹é«”ä¸­æ–‡å’Œè‹±æ–‡å›ç­”é—œæ–¼å“ˆåˆ©æ³¢ç‰¹çš„å•é¡Œã€‚"
        "åªéœ€ç”¨ä»»ä½•ä¸€ç¨®èªè¨€è¼¸å…¥æ‚¨çš„å•é¡Œï¼Œæ©Ÿå™¨äººå°±æœƒç›¸æ‡‰åœ°å›ç­”ã€‚"
    )
    
    # æ·»åŠ å…è²¬è²æ˜
    st.sidebar.warning(
        "Disclaimer: The answers generated by this model might contain errors. Please evaluate the responses with caution."
    )
    st.sidebar.warning(
        "å…è²¬è²æ˜ï¼šæ¨¡å‹ç”Ÿæˆçš„å›ç­”å¯èƒ½æœ‰èª¤ï¼Œè«‹è¬¹æ…è©•ä¼°å›è¦†å…§å®¹ã€‚"
    )

if __name__ == "__main__":
    main()
